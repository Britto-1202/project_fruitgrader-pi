
import cv2
import numpy as np
import tensorflow as tf
import pyttsx3

# Load the pre-trained ML model
model = tf.keras.models.load_model('fruit_model.h5')

# Initialize the text-to-speech engine
engine = pyttsx3.init()

# Start capturing video from webcam
cap = cv2.VideoCapture(0)

# Set the frame size
cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)
cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)

# Define the crop region for the fruit
x, y, w, h = 200, 100, 200, 200

while True:
    # Read a frame from the video stream
    ret, frame = cap.read()

    # Crop the region of interest containing the fruit
    fruit = frame[y:y+h, x:x+w]

    # Display the cropped image
    cv2.imshow('Fruit', fruit)

    # Save the cropped image to file
    cv2.imwrite('fruit.jpg', fruit)

    # Load the saved image and preprocess it for the ML model
    img = cv2.imread('fruit.jpg')
    img = cv2.resize(img, (224, 224))
    img = img / 255.0
    img = np.expand_dims(img, axis=0)

    # Pass the image to the ML model and get the prediction
    pred = model.predict(img)[0]

    # Display the prediction
    if pred[0] > 0.5:
        prediction = 'Fresh fruit detected'
    else:
        prediction = 'Rotten fruit detected'

    print(prediction)
    engine.say(prediction)
    engine.runAndWait()

    # Wait for key press
    if cv2.waitKey(1) & 0xFF == ord('q'):
        break

# Release the capture and destroy all windows
cap.release()
cv2.destroyAllWindows()



pyttsx3
import cv2
import numpy as np
import tensorflow as tf
import pyttsx3
import Adafruit_CharLCD as LCD

# Load the pre-trained ML model
model = tf.keras.models.load_model('fruits_data.h5')

# Initialize the text-to-speech engine
engine = pyttsx3.init()

# Initialize the LCD display
lcd = LCD.Adafruit_CharLCD(rs=26, en=19, d4=13, d5=6, d6=5, d7=11, cols=16, rows=2)

# Start capturing video from webcam
cap = cv2.VideoCapture(0)

# Set the frame size
cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)
cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)

# Define the crop region for the fruit
x, y, w, h = 200, 100, 200, 200

while True:
    # Read a frame from the video stream
    ret, frame = cap.read()

    # Display the original frame
    cv2.imshow('Fruit Detector', frame)

    # Wait for key press
    key = cv2.waitKey(1)
    if key == ord('q'):
        break
    elif key == ord(' '):
        # Capture the image and save it to a file
        fruit = frame[y:y+h, x:x+w]
        cv2.imwrite('fruit.jpg', fruit)

        # Preprocess the image for the ML model
        img = tf.keras.preprocessing.image.img_to_array(fruit)
        img = tf.keras.preprocessing.image.smart_resize(img, (224, 224))
        img = tf.keras.applications.mobilenet_v2.preprocess_input(img)

        # Pass the image to the ML model and get the prediction
        preds = model.predict(np.expand_dims(img, axis=0))
        print(preds)

        # Define a dictionary to map indices to fruit labels
        label_dict = {0: "fresh apple", 1: "fresh banana", 2: "fresh orange",
                      3: "rotten apple", 4: "rotten banana", 5: "rotten orange"}

        # Get the index of the maximum value in the preds array
        pred_index = np.argmax(preds)
        print(pred_index)
        # Check if the predicted class is above the threshold
        if preds[0][pred_index] > 0.5:
            # Get




import cv2
import numpy as np
import tensorflow as tf
import pyttsx3
from RPLCD.i2c import CharLCD

# Load the pre-trained ML model
model = tf.keras.models.load_model('fruits_data.h5')

# Initialize the text-to-speech engine
engine = pyttsx3.init()

# Initialize the LCD
lcd = CharLCD('PCF8574', 0x27)

# Start capturing video from webcam
cap = cv2.VideoCapture(0)

# Set the frame size
cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)
cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)

# Define the crop region for the fruit
x, y, w, h = 200, 100, 200, 200

while True:
    # Read a frame from the video stream
    ret, frame = cap.read()

    # Display the original frame
    cv2.imshow('Fruit Detector', frame)

    # Wait for key press
    key = cv2.waitKey(1)
    if key == ord('q'):
        break
    elif key == ord(' '):
        # Capture the image and save it to a file
        fruit = frame[y:y+h, x:x+w]
        cv2.imwrite('fruit.jpg', fruit)

        # Preprocess the image for the ML model
        img = tf.keras.preprocessing.image.img_to_array(fruit)
        img = tf.keras.preprocessing.image.smart_resize(img, (224, 224))
        img = tf.keras.applications.mobilenet_v2.preprocess_input(img)

        # Pass the image to the ML model and get the prediction
        preds = model.predict(np.expand_dims(img, axis=0))
        print(preds)

        # Define a dictionary to map indices to fruit labels
        label_dict = {0: "fresh apple", 1: "fresh banana", 2: "fresh orange",
                      3: "rotten apple", 4: "rotten banana", 5: "rotten orange"}

        # Get the index of the maximum value in the preds array
        pred_index = np.argmax(preds)
        print(pred_index)
        # Check if the predicted class is above the threshold
        if preds[0][pred_index] > 0.5:
            # Get the corresponding fruit label from the dictionary
            label = label_dict[pred_index]
            print(f"The fruit is a {label}.")
            # Speak the label
            engine.say(f"The fruit is a {label}.")
            engine.runAndWait()
            # Display the label on the LCD
            lcd.clear()
            lcd.write_string(f"The fruit is a {label}.")
        else:
            print("Please show a valid image.")
            # Speak an error message
            engine.say("Please show a valid image.")
            engine.runAndWait()
            # Display the error message on the LCD
            lcd.clear()
            lcd.write_string("Please show a valid image.")

# Release the capture and destroy all windows
cap.release()
cv2
